{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import vizdoom\n",
    "import numpy as np\n",
    "import mss\n",
    "import time\n",
    "import mss.tools\n",
    "\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Doom Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(Env): \n",
    "    def __init__(self, render=False, config='ViZDoom/scenarios/health_gathering.cfg'): \n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.game = vizdoom.DoomGame()\n",
    "        self.game.load_config(config)\n",
    "        \n",
    "\n",
    "        if render == False: \n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        \n",
    "\n",
    "        self.game.init()\n",
    "        \n",
    "\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8) \n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "        \n",
    "    def step(self, action, tics):\n",
    "\n",
    "        actions = np.identity(3)\n",
    "        movement_reward = self.game.make_action(actions[action], tics) \n",
    "        \n",
    "        reward = 0\n",
    "\n",
    "        if self.game.get_state(): \n",
    "            state = self.game.get_state().screen_buffer\n",
    "    \n",
    "            game_variables = self.game.get_state().game_variables\n",
    "            health = game_variables\n",
    "            \n",
    "            reward = movement_reward \n",
    "            info = health\n",
    "        else: \n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0 \n",
    "        \n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        return state, reward, done, info \n",
    "    \n",
    "    def render(): \n",
    "        pass\n",
    "    \n",
    "    def reset(self): \n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return state\n",
    "    \n",
    "    def close(self): \n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a single action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)\n",
    "tics = 1\n",
    "states = []\n",
    "infos = []\n",
    "for episode in range(1): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(1, tics)\n",
    "        states.append(obs)\n",
    "        infos.append(info)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Head for the VLM model\n",
    "class VLMWithValueHead(nn.Module):\n",
    "    def __init__(self, vlm_model, device=\"cuda\"):\n",
    "        super(VLMWithValueHead, self).__init__()\n",
    "        self.vlm_model = vlm_model\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(vlm_model.config.hidden_size, 256, dtype=torch.bfloat16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1, dtype=torch.bfloat16)\n",
    "        ).to(device)\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.vlm_model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1][:, -1, :]\n",
    "        value = self.value_head(hidden_states)\n",
    "        return outputs, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "model_path = \"./vlm_ppo_model_iter_20.pt\"\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\", torch_dtype=\"auto\", device_map=\"mps\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "\n",
    "model = VLMWithValueHead(model, device=device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vlm_action(state, info, model=model, processor=processor, device=\"mps\"):\n",
    "\n",
    "    try:\n",
    "        # Ensure state is in the right format\n",
    "        if state.ndim == 3 and state.shape[0] in [1, 3]:  \n",
    "            state = np.transpose(state, (1, 2, 0)) \n",
    "        elif state.ndim == 2:\n",
    "            state = np.stack([state] * 3, axis=-1) \n",
    "            \n",
    "        img = Image.fromarray(state.astype(np.uint8))\n",
    "        \n",
    "        health = str(info[\"info\"][0].item() if isinstance(info[\"info\"], np.ndarray) else info[\"info\"])\n",
    "        \n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": img},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"\"\"You are in a game environment where your life is constantly decreasing, collect health \n",
    "                    packages present in the environment to survive. You are given with the current state of the game, \n",
    "                    you need to choose and action: MOVELEFT, MOVERIGHT, STRAIGHT.\n",
    "\n",
    "                    Write out the reason why you are choosing an action in one concise sentence and choose an action in the shown format.\n",
    "                    Current health: {health}.\n",
    "\n",
    "                    Output format: {{ REASON: (reasoning in one line), ACTION: (one of MOVELEFT, MOVERIGHT, STRAIGHT) }}\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        \n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        \n",
    "        inputs = processor(\n",
    "            text=text,\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        for k, v in inputs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.vlm_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=128,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        input_length = inputs[\"input_ids\"].shape[1]\n",
    "        generated_text = processor.decode(\n",
    "            generated_ids[0, input_length:],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        action_text = generated_text.upper()\n",
    "        \n",
    "        if \"MOVERIGHT\" in action_text:\n",
    "            action = 1\n",
    "        elif \"MOVELEFT\" in action_text:\n",
    "            action = 0\n",
    "        elif \"STRAIGHT\" in action_text:\n",
    "            action = 2\n",
    "        else:\n",
    "\n",
    "            action = 2\n",
    "        \n",
    "        return action, generated_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in vlm_action: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 2, f\"Error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)\n",
    "replay_buffer = []\n",
    "tics = 4\n",
    "\n",
    "for episode in range(2): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    info = {'info': np.array([100.0])}\n",
    "    health_info = info['info'][0].item()\n",
    "    while not done: \n",
    "        action, reasoning = vlm_action(obs, info)\n",
    "        obs, reward, done, info = env.step(action, tics)\n",
    "        current_health_info = info['info'][0].item()\n",
    "        if health_info >= current_health_info:\n",
    "            health_info = current_health_info\n",
    "            reward = reward - tics\n",
    "        else:\n",
    "            reward = 10 * tics\n",
    "            health_info = current_health_info\n",
    "        total_reward += reward\n",
    "        \n",
    "        print(info, reasoning, reward)\n",
    "        replay_buffer.append([action, reward, info['info'][0].item(), reasoning])\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
